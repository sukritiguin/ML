{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf548d7",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ba3dfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string,time\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import spacy\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a42aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5aefbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e69f686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900e245",
   "metadata": {},
   "source": [
    "# Steps :\n",
    "\n",
    ">## 1. Conversting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4a3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa869d",
   "metadata": {},
   "source": [
    ">## 2. Recomving HTML Tags\n",
    "\n",
    ">https://regex101.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a861274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_HTML_Tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11734eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_HTML_Tags(df['review'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b65bc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c65524d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].apply(remove_HTML_Tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c1bab",
   "metadata": {},
   "source": [
    ">## 3. Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7759dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6081edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the website names '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(\"this is the website names http://www.nsec.ac.in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34211a1c",
   "metadata": {},
   "source": [
    ">## 4. Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "237bc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "359384c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dca6fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    exclude = string.punctuation\n",
    "    for ch in exclude:\n",
    "        text = text.replace(ch,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98e80737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this  is the great  text with  puntuationns'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuations(\"this !! is the great @# text with . puntuationns..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "129a7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this short film that inspired the soontobe full length feature  spatula madness  is a hilarious piece that contends against similar cartoons yielding multiple writers the short film stars edward the spatula who after being fired from his job joins in the fight against the evil spoons this premise allows for some funny content near the beginning but is barely present for the remainder of the feature this films 15minute running time is absorbed by some oddball comedy and a small musical number unfortunately not much else lies below it the plot that is set up doesnt really have time to show but its surely follows it plot better than many highbudget hollywood films this film is worth watching at least a few times take it for what it is and dont expect a deep story\n",
      "\n",
      "Time taking : 0.002240896224975586 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punctuations(df['review'][100]) + \"\\n\")\n",
    "time1 = time.time() - start\n",
    "print(\"Time taking : \" + str(time.time() - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9404311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anotern fuction to remove puntuations in a very fast way\n",
    "def remove_puch(text):\n",
    "    return text.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d3b988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this short film that inspired the soontobe full length feature  spatula madness  is a hilarious piece that contends against similar cartoons yielding multiple writers the short film stars edward the spatula who after being fired from his job joins in the fight against the evil spoons this premise allows for some funny content near the beginning but is barely present for the remainder of the feature this films 15minute running time is absorbed by some oddball comedy and a small musical number unfortunately not much else lies below it the plot that is set up doesnt really have time to show but its surely follows it plot better than many highbudget hollywood films this film is worth watching at least a few times take it for what it is and dont expect a deep story\n",
      "\n",
      "Time taking : 0.001001119613647461 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_puch(df['review'][100]) + \"\\n\")\n",
    "time2 = time.time() - start\n",
    "print(\"Time taking : \" + str(time.time() - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "337eea38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.238390092879257"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1/time2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91316450",
   "metadata": {},
   "source": [
    ">## 5. Chat Word Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "101ea3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open text file in read mode\n",
    "text_file = open(\"slag.txt\", \"r\")\n",
    " \n",
    "#read whole file to a string\n",
    "data = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b158aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(\"=\",\":\")\n",
    "data = data.replace(\"\\n\",\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5ff7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('slag.txt', 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899b382",
   "metadata": {},
   "source": [
    "AFAIK:As Far As I Know,\n",
    "\n",
    "AFK:Away From Keyboard,\n",
    "\n",
    "ASAP:As Soon As Possible,\n",
    "\n",
    "ATK:At The Keyboard,\n",
    "\n",
    "ATM:At The Moment,\n",
    "\n",
    "A3:Anytime, Anywhere, Anyplace,\n",
    "\n",
    "BAK:Back At Keyboard,\n",
    "\n",
    "BBL:Be Back Later,\n",
    "\n",
    "BBS:Be Back Soon,\n",
    "\n",
    "BFN:Bye For Now,\n",
    "\n",
    "B4N:Bye For Now,\n",
    "\n",
    "BRB:Be Right Back,\n",
    "\n",
    "BRT:Be Right There,\n",
    "\n",
    "BTW:By The Way,\n",
    "\n",
    "B4:Before,\n",
    "\n",
    "B4N:Bye For Now,\n",
    "\n",
    "CU:See You,\n",
    "\n",
    "CUL8R:See You Later,\n",
    "\n",
    "CYA:See You,\n",
    "\n",
    "FAQ:Frequently Asked Questions,\n",
    "\n",
    "FC:Fingers Crossed,\n",
    "\n",
    "FWIW:For What It's Worth,\n",
    "\n",
    "FYI:For Your Information,\n",
    "\n",
    "GAL:Get A Life,\n",
    "\n",
    "GG:Good Game,\n",
    "\n",
    "GN:Good Night,\n",
    "\n",
    "GMTA:Great Minds Think Alike,\n",
    "\n",
    "GR8:Great!,\n",
    "\n",
    "G9:Genius,\n",
    "\n",
    "IC:I See,\n",
    "\n",
    "ICQ:I Seek you (also a chat program),\n",
    "\n",
    "ILU:ILU: I Love You,\n",
    "\n",
    "IMHO:In My Honest/Humble Opinion,\n",
    "\n",
    "IMO:In My Opinion,\n",
    "\n",
    "IOW:In Other Words,\n",
    "\n",
    "IRL:In Real Life,\n",
    "\n",
    "KISS:Keep It Simple, Stupid,\n",
    "\n",
    "LDR:Long Distance Relationship,\n",
    "\n",
    "LMAO:Laugh My A.. Off,\n",
    "\n",
    "LOL:Laughing Out Loud,\n",
    "\n",
    "LTNS:Long Time No See,\n",
    "\n",
    "L8R:Later,\n",
    "\n",
    "MTE:My Thoughts Exactly,\n",
    "\n",
    "M8:Mate,\n",
    "\n",
    "NRN:No Reply Necessary,\n",
    "\n",
    "OIC:Oh I See,\n",
    "\n",
    "PITA:Pain In The A..,\n",
    "\n",
    "PRT:Party,\n",
    "\n",
    "PRW:Parents Are Watching,\n",
    "\n",
    "ROFL:Rolling On The Floor Laughing,\n",
    "\n",
    "ROFLOL:Rolling On The Floor Laughing Out Loud,\n",
    "\n",
    "ROTFLMAO:Rolling On The Floor Laughing My A.. Off,\n",
    "\n",
    "SK8:Skate,\n",
    "\n",
    "STATS:Your sex and age,\n",
    "\n",
    "ASL:Age, Sex, Location,\n",
    "\n",
    "THX:Thank You,\n",
    "\n",
    "TTFN:Ta-Ta For Now!,\n",
    "\n",
    "TTYL:Talk To You Later,\n",
    "\n",
    "U:You,\n",
    "\n",
    "U2:You Too,\n",
    "\n",
    "U4E:Yours For Ever,\n",
    "\n",
    "WB:Welcome Back,\n",
    "\n",
    "WTF:What The F...,\n",
    "\n",
    "WTG:Way To Go!,\n",
    "\n",
    "WUF:Where Are You From?,\n",
    "\n",
    "W8:Wait...,\n",
    "\n",
    "7K:Sick:-D Laugher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b99f75",
   "metadata": {},
   "source": [
    ">## 6. Spelling Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f292ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a97751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_the_text(text):\n",
    "    textBlb = TextBlob(text)\n",
    "    return textBlb.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "543aee29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this a good boy and intelligent'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_the_text(\"thiis a goood boi and inteligent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555fd42f",
   "metadata": {},
   "source": [
    ">## 7. Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a6f360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2bc621ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "542968de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopWords(text):\n",
    "    stopWords = stopwords.words('english')\n",
    "    lst = []\n",
    "    for word in text.split():\n",
    "        if word not in stopWords:\n",
    "            lst.append(word)\n",
    "    return \" \".join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4cc7765c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good boy apple'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopWords(\"this is a good boy and he has an apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87898be9",
   "metadata": {},
   "source": [
    ">## 8. Emojy Handling\n",
    "\n",
    "> Two Ways : \n",
    ">1. Remove emoji from text\n",
    ">2. Replace emoji with actual meaning\n",
    "\n",
    ">### Replacing emoji with NULL using `re`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de516867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "74e5e30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lmao '"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Lmao 😂😂\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "19086dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie. It was '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Loved the movie. It was 😘😘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94b490",
   "metadata": {},
   "source": [
    ">### Replacing Emoji with actual meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f2874d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':rolling_on_the_floor_laughing::red_heart:'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "emoji.demojize(\"🤣❤️\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24aa1393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This move is just awesome, I :red_heart: it soo much.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.demojize(\"This move is just awesome, I ❤️ it soo much.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82533307",
   "metadata": {},
   "source": [
    ">## 9. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "41f905f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96a9ca77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'Ph.D', 'in', 'A.I', '.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"I have Ph.D in A.I.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c1bb8a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have Ph.D in A.I.', 'My friend has M.Sc in Physics.']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(\"I have Ph.D in A.I. My friend has M.Sc in Physics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7ebb56b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'email',\n",
       " 'is',\n",
       " 'sukritiguin1234',\n",
       " '@',\n",
       " 'gmail.com',\n",
       " '.',\n",
       " 'We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'go',\n",
       " 'with',\n",
       " 'you',\n",
       " \"'\",\n",
       " 'r',\n",
       " 'home',\n",
       " '.']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"My email is sukritiguin1234@gmail.com. We're here to go with you'r home.\") #Fails here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b4d10c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "945cd1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'spacy' from 'C:\\\\Users\\\\LENOVO\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\spacy\\\\__init__.py'>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0181fd2",
   "metadata": {},
   "source": [
    "`C:\\Users\\LENOVO\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "456b51c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1f852b89de0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1d193fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My\n",
      "email\n",
      "is\n",
      "sukritiguin1234@gmail.com\n",
      ".\n",
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "go\n",
      "with\n",
      "you'r\n",
      "home\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"My email is sukritiguin1234@gmail.com. We're here to go with you'r home.\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f73c8136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "5\n",
      "km\n",
      "distance\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is 5km distance.\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4232d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"This is 5km distance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e0e51b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(type(str(token)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858cbc2",
   "metadata": {},
   "source": [
    ">## 10. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f39b2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "423a4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    ps = PorterStemmer()\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    return \" \".join([ps.stem(str(token)) for token in nlp(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f3b15cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk wlak'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_text(\"Walk walking walked wlaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "956179c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl he is in kitchen'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_text(\"Probably he is in kitchen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804befb8",
   "metadata": {},
   "source": [
    ">## 11. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ddc3a361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1b5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
